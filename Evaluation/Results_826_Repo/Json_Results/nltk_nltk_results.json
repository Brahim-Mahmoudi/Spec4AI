{
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/misc/wordfinder.py": {
    "R2": [
      "Random Seed Not Set at line 122",
      "Random Seed Not Set at line 16",
      "Random Seed Not Set at line 89",
      "Random Seed Not Set at line 90",
      "Random Seed Not Set at line 91",
      "Random Seed Not Set at line 92",
      "Random Seed Not Set at line 113"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/misc/chomsky.py": {
    "R2": [
      "Random Seed Not Set at line 127"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/text.py": {
    "R11bis": [
      "Potential data leakage: model.fit() used without a pipeline at line 566"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/cluster/api.py": {
    "R17": [
      "Unnecessary iteration detected; consider using vectorized operations (e.g., DataFrame.add, tf.reduce_sum) for efficiency at line 50"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/cluster/em.py": {
    "R17": [
      "Unnecessary iteration detected; consider using vectorized operations (e.g., DataFrame.add, tf.reduce_sum) for efficiency at line 109",
      "Unnecessary iteration detected; consider using vectorized operations (e.g., DataFrame.add, tf.reduce_sum) for efficiency at line 114"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/metrics/aline.py": {
    "R12": [
      "Use np.matmul() instead of np.dot() for matrices at line 1463"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/classify/scikitlearn.py": {
    "R11bis": [
      "Potential data leakage: model.fit() used without a pipeline at line 114"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/probability.py": {
    "R17": [
      "Unnecessary iteration detected; consider using vectorized operations (e.g., DataFrame.add, tf.reduce_sum) for efficiency at line 203",
      "Unnecessary iteration detected; consider using vectorized operations (e.g., DataFrame.add, tf.reduce_sum) for efficiency at line 1070",
      "Unnecessary iteration detected; consider using vectorized operations (e.g., DataFrame.add, tf.reduce_sum) for efficiency at line 1734",
      "Unnecessary iteration detected; consider using vectorized operations (e.g., DataFrame.add, tf.reduce_sum) for efficiency at line 2063"
    ],
    "R2": [
      "Random Seed Not Set at line 578",
      "Random Seed Not Set at line 593",
      "Random Seed Not Set at line 658",
      "Random Seed Not Set at line 2437"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/classify/decisiontree.py": {
    "R5": [
      "Hyperparameter not explicitly set at line 191",
      "Hyperparameter not explicitly set at line 204",
      "Hyperparameter not explicitly set at line 297",
      "Hyperparameter not explicitly set at line 203",
      "Hyperparameter not explicitly set at line 295",
      "Hyperparameter not explicitly set at line 293"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/chat/util.py": {
    "R2": [
      "Random Seed Not Set at line 102"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/test/unit/lm/test_models.py": {
    "R11bis": [
      "Potential data leakage: model.fit() used without a pipeline at line 49",
      "Potential data leakage: model.fit() used without a pipeline at line 132",
      "Potential data leakage: model.fit() used without a pipeline at line 160",
      "Potential data leakage: model.fit() used without a pipeline at line 223",
      "Potential data leakage: model.fit() used without a pipeline at line 249",
      "Potential data leakage: model.fit() used without a pipeline at line 316",
      "Potential data leakage: model.fit() used without a pipeline at line 373",
      "Potential data leakage: model.fit() used without a pipeline at line 425",
      "Potential data leakage: model.fit() used without a pipeline at line 474",
      "Potential data leakage: model.fit() used without a pipeline at line 516",
      "Potential data leakage: model.fit() used without a pipeline at line 574"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/translate/stack_decoder.py": {
    "R17": [
      "Unnecessary iteration detected; consider using vectorized operations (e.g., DataFrame.add, tf.reduce_sum) for efficiency at line 267"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/corpus/reader/xmldocs.py": {
    "R17": [
      "Unnecessary iteration detected; consider using vectorized operations (e.g., DataFrame.add, tf.reduce_sum) for efficiency at line 324"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/parse/pchart.py": {
    "R2": [
      "Random Seed Not Set at line 399"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/sem/logic.py": {
    "R17": [
      "Unnecessary iteration detected; consider using vectorized operations (e.g., DataFrame.add, tf.reduce_sum) for efficiency at line 224"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/parse/transitionparser.py": {
    "R11bis": [
      "Potential data leakage: model.fit() used without a pipeline at line 539"
    ],
    "R22": [
      "Call to a sensitive function detected without prior scaling; consider applying a scaler (e.g., StandardScaler) before executing scale-sensitive operations at line 539"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/tag/perceptron.py": {
    "R2": [
      "Random Seed Not Set at line 246"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/tag/tnt.py": {
    "R17": [
      "Unnecessary iteration detected; consider using vectorized operations (e.g., DataFrame.add, tf.reduce_sum) for efficiency at line 200",
      "Unnecessary iteration detected; consider using vectorized operations (e.g., DataFrame.add, tf.reduce_sum) for efficiency at line 206"
    ]
  },
  "/Users/bramss/Desktop/All_Repo/nltk_nltk/nltk-develop/nltk/draw/tree.py": {
    "R17": [
      "Unnecessary iteration detected; consider using vectorized operations (e.g., DataFrame.add, tf.reduce_sum) for efficiency at line 372"
    ],
    "R2": [
      "Random Seed Not Set at line 1021",
      "Random Seed Not Set at line 1055",
      "Random Seed Not Set at line 1058"
    ]
  }
}